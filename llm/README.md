# ğŸ¤– Farmer LLM Assistant System

Advanced Large Language Model system for intelligent farmer responses. Takes NLP intent output and generates human-like, contextual farming advice.

## ğŸ¯ **System Overview**

### **Complete Pipeline:**
```
ğŸ¤ Speech Input â†’ ğŸ§  NLP Intent â†’ ğŸ¤– LLM Response â†’ ğŸ‘¨â€ğŸŒ¾ Farmer
```

### **Key Features:**
- **ğŸ¤– LLM-Powered**: Uses Ollama with Llama 3.2 for intelligent responses
- **ğŸŒ¾ Farmer-Specific**: Specialized prompts for agricultural advice
- **ğŸ—£ï¸ Multi-language**: Hindi + English support with natural responses
- **âš¡ Real-time**: Fast response generation (<5 seconds)
- **ğŸ¯ Context-Aware**: Uses NLP intent and entities for targeted advice
- **ğŸ’¬ Human-like**: Natural, conversational responses

## ğŸ“ **Project Structure**

```
llm/
â”œâ”€â”€ ğŸ¤– Core LLM System
â”‚   â”œâ”€â”€ farmer_llm_assistant.py        # â­ Main LLM engine
â”‚   â”œâ”€â”€ complete_farmer_assistant.py   # Full STTâ†’NLPâ†’LLM pipeline
â”‚   â””â”€â”€ requirements.txt               # Dependencies
â”‚
â”œâ”€â”€ ğŸ“š Documentation & Setup
â”‚   â”œâ”€â”€ README.md                      # This file
â”‚   â”œâ”€â”€ OLLAMA_SETUP.md               # Ollama installation guide
â”‚   â””â”€â”€ LLM_EXAMPLES.md               # Usage examples (to be created)
â”‚
â””â”€â”€ ğŸ§ª Testing & Validation
    â””â”€â”€ test_llm.py                   # LLM testing script (to be created)
```

## ğŸš€ **Quick Start**

### **Prerequisites:**
1. **Ollama installed and running**
2. **Model downloaded** (llama3.2:3b recommended)
3. **NLP system working** (from ../nlp/)
4. **Python dependencies** installed

### **Step 1: Setup Ollama**
```bash
# Install Ollama (see OLLAMA_SETUP.md for details)
# Windows: Download from https://ollama.ai
# Linux/Mac: curl -fsSL https://ollama.ai/install.sh | sh

# Start Ollama
ollama serve

# Pull recommended model
ollama pull llama3.2:3b
```

### **Step 2: Install Dependencies**
```bash
cd llm
pip install -r requirements.txt
```

### **Step 3: Test LLM System**
```bash
# Test standalone LLM
python farmer_llm_assistant.py

# Test complete pipeline
python complete_farmer_assistant.py
```

## ğŸ¤ **Usage Examples**

### **Standalone LLM Testing:**
```bash
cd llm
python farmer_llm_assistant.py
```

**Example Interaction:**
```
ğŸ¤ à¤†à¤ªà¤•à¤¾ à¤¸à¤µà¤¾à¤²: à¤®à¥à¤à¥‡ à¤—à¥‡à¤¹à¥‚à¤‚ à¤•à¥‡ à¤²à¤¿à¤ à¤–à¤¾à¤¦ à¤•à¥€ à¤¸à¤²à¤¾à¤¹ à¤šà¤¾à¤¹à¤¿à¤

ğŸ” Step 1: Detecting intent...
ğŸ¯ Intent: fertilizer_advice (Confidence: 0.80)
ğŸ·ï¸ Entities: {'crops': ['wheat']}

ğŸ¤– Step 2: Generating LLM response...
ğŸ¤– LLM Response Time: 3.2s

ğŸŒ¾ à¤•à¤¿à¤¸à¤¾à¤¨ à¤¸à¤¹à¤¾à¤¯à¤• à¤•à¤¾ à¤œà¤µà¤¾à¤¬:
à¤—à¥‡à¤¹à¥‚à¤‚ à¤•à¥‡ à¤²à¤¿à¤ 120:60:40 NPK à¤…à¤¨à¥à¤ªà¤¾à¤¤ à¤®à¥‡à¤‚ à¤–à¤¾à¤¦ à¤¦à¥‡à¤‚à¥¤ à¤¬à¥à¤†à¤ˆ à¤•à¥‡ à¤¸à¤®à¤¯ DAP à¤”à¤° à¤¯à¥‚à¤°à¤¿à¤¯à¤¾ à¤•à¤¾ à¤ªà¥à¤°à¤¯à¥‹à¤— à¤•à¤°à¥‡à¤‚à¥¤ à¤®à¤¿à¤Ÿà¥à¤Ÿà¥€ à¤ªà¤°à¥€à¤•à¥à¤·à¤£ à¤•à¤°à¤¾à¤•à¤° à¤œà¤¿à¤‚à¤• à¤”à¤° à¤¸à¤²à¥à¤«à¤° à¤•à¥€ à¤•à¤®à¥€ à¤­à¥€ à¤ªà¥‚à¤°à¥€ à¤•à¤°à¥‡à¤‚à¥¤
```

### **Complete Pipeline:**
```bash
cd llm
python complete_farmer_assistant.py
```

**Real-time Speech Interaction:**
```
ğŸ¤ [User speaks]: "à¤®à¥‡à¤°à¥€ à¤«à¤¸à¤² à¤®à¥‡à¤‚ à¤•à¥€à¤¡à¤¼à¥‡ à¤²à¤— à¤—à¤ à¤¹à¥ˆà¤‚"

ğŸ”„ Processing through pipeline...
  ğŸ§  Step 1: Detecting intent...
  ğŸ¯ Intent: crop_disease (Confidence: 0.85)
  ğŸ¤– Step 2: Generating intelligent response...

ğŸŒ¾ à¤•à¤¿à¤¸à¤¾à¤¨ à¤¸à¤¹à¤¾à¤¯à¤• à¤•à¤¾ à¤œà¤µà¤¾à¤¬:
à¤¤à¥à¤°à¤‚à¤¤ à¤•à¥€à¤Ÿà¤¨à¤¾à¤¶à¤• à¤•à¤¾ à¤›à¤¿à¤¡à¤¼à¤•à¤¾à¤µ à¤•à¤°à¥‡à¤‚à¥¤ à¤‡à¤®à¤¿à¤¡à¤¾à¤•à¥à¤²à¥‹à¤ªà¥à¤°à¤¿à¤¡ à¤¯à¤¾ à¤•à¥à¤²à¥‹à¤°à¤ªà¤¾à¤¯à¤°à¤¿à¤«à¥‰à¤¸ à¤•à¤¾ à¤ªà¥à¤°à¤¯à¥‹à¤— à¤•à¤° à¤¸à¤•à¤¤à¥‡ à¤¹à¥ˆà¤‚à¥¤ à¤¶à¤¾à¤® à¤•à¥‡ à¤¸à¤®à¤¯ à¤›à¤¿à¤¡à¤¼à¤•à¤¾à¤µ à¤•à¤°à¥‡à¤‚ à¤”à¤° 15 à¤¦à¤¿à¤¨ à¤¬à¤¾à¤¦ à¤¦à¥‹à¤¬à¤¾à¤°à¤¾ à¤•à¤°à¥‡à¤‚à¥¤

â±ï¸ Response Time: 4.1s
ğŸ“Š Confidence: 0.85
ğŸ¯ Intent: crop_disease
```

## ğŸ§  **LLM System Architecture**

### **Intent-Specific Prompts:**
```python
farmer_prompts = {
    "seed_inquiry": {
        "system_prompt": "à¤†à¤ª à¤à¤• à¤…à¤¨à¥à¤­à¤µà¥€ à¤•à¥ƒà¤·à¤¿ à¤µà¤¿à¤¶à¥‡à¤·à¤œà¥à¤ à¤¹à¥ˆà¤‚ à¤œà¥‹ à¤¬à¥€à¤œ à¤•à¥€ à¤¸à¤²à¤¾à¤¹ à¤¦à¥‡à¤¤à¥‡ à¤¹à¥ˆà¤‚...",
        "context": "à¤¬à¥€à¤œ à¤•à¥€ à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤”à¤° à¤¸à¤²à¤¾à¤¹"
    },
    
    "fertilizer_advice": {
        "system_prompt": "à¤†à¤ª à¤à¤• à¤®à¤¿à¤Ÿà¥à¤Ÿà¥€ à¤”à¤° à¤‰à¤°à¥à¤µà¤°à¤• à¤µà¤¿à¤¶à¥‡à¤·à¤œà¥à¤ à¤¹à¥ˆà¤‚...",
        "context": "à¤–à¤¾à¤¦ à¤”à¤° à¤‰à¤°à¥à¤µà¤°à¤• à¤•à¥€ à¤¸à¤²à¤¾à¤¹"
    },
    
    "crop_disease": {
        "system_prompt": "à¤†à¤ª à¤à¤• à¤ªà¥Œà¤§à¥‹à¤‚ à¤•à¥‡ à¤°à¥‹à¤— à¤µà¤¿à¤¶à¥‡à¤·à¤œà¥à¤ à¤¹à¥ˆà¤‚...",
        "context": "à¤«à¤¸à¤² à¤°à¥‹à¤— à¤”à¤° à¤•à¥€à¤Ÿ à¤¨à¤¿à¤¯à¤‚à¤¤à¥à¤°à¤£"
    }
}
```

### **Response Generation Process:**
1. **Intent Analysis**: Receive NLP intent + entities
2. **Prompt Selection**: Choose appropriate system prompt
3. **Context Building**: Add entity information and user query
4. **LLM Generation**: Send to Ollama API
5. **Response Cleaning**: Format and clean output
6. **Fallback Handling**: Provide backup response if LLM fails

## ğŸ¯ **Supported Farming Intents**

| Intent | LLM Specialization | Example Response |
|--------|-------------------|------------------|
| **seed_inquiry** | Seed varieties, timing, quantity | "à¤—à¥‡à¤¹à¥‚à¤‚ à¤•à¥‡ à¤²à¤¿à¤ HD-2967 à¤•à¤¿à¤¸à¥à¤® à¤…à¤šà¥à¤›à¥€ à¤¹à¥ˆà¥¤ à¤¨à¤µà¤‚à¤¬à¤° à¤®à¥‡à¤‚ à¤¬à¥à¤†à¤ˆ à¤•à¤°à¥‡à¤‚à¥¤" |
| **fertilizer_advice** | NPK ratios, application timing | "120:60:40 NPK à¤…à¤¨à¥à¤ªà¤¾à¤¤ à¤¦à¥‡à¤‚à¥¤ à¤¬à¥à¤†à¤ˆ à¤•à¥‡ à¤¸à¤®à¤¯ DAP à¤¡à¤¾à¤²à¥‡à¤‚à¥¤" |
| **crop_disease** | Disease identification, treatment | "à¤¯à¤¹ à¤¬à¥à¤²à¤¾à¤¸à¥à¤Ÿ à¤°à¥‹à¤— à¤¹à¥ˆà¥¤ à¤Ÿà¥à¤°à¤¾à¤‡à¤¸à¤¾à¤‡à¤•à¥à¤²à¤¾à¤œà¥‹à¤² à¤•à¤¾ à¤›à¤¿à¤¡à¤¼à¤•à¤¾à¤µ à¤•à¤°à¥‡à¤‚à¥¤" |
| **market_price** | Price trends, selling advice | "à¤†à¤œ à¤—à¥‡à¤¹à¥‚à¤‚ â‚¹2200 à¤ªà¥à¤°à¤¤à¤¿ à¤•à¥à¤µà¤¿à¤‚à¤Ÿà¤² à¤¹à¥ˆà¥¤ eNAM à¤ªà¤° à¤¬à¥‡à¤šà¥‡à¤‚à¥¤" |
| **irrigation_need** | Watering schedule, methods | "à¤—à¥‡à¤¹à¥‚à¤‚ à¤®à¥‡à¤‚ 4-5 à¤¸à¤¿à¤‚à¤šà¤¾à¤ˆ à¤šà¤¾à¤¹à¤¿à¤à¥¤ à¤ªà¤¹à¤²à¥€ 20 à¤¦à¤¿à¤¨ à¤¬à¤¾à¤¦à¥¤" |

## âš™ï¸ **Configuration Options**

### **Model Selection:**
```python
# Fast but basic
model_name = "llama3.2:1b"

# Balanced (recommended)
model_name = "llama3.2:3b"

# High quality but slow
model_name = "llama3.1:8b"
```

### **Response Parameters:**
```python
ollama_request = {
    "model": "llama3.2:3b",
    "temperature": 0.7,    # Creativity (0.1-1.0)
    "top_p": 0.9,         # Diversity
    "max_tokens": 200,    # Response length
    "stop": ["\n\n"]      # Stop sequences
}
```

### **Language Settings:**
```python
# Primary language for responses
primary_language = "hindi"

# Fallback language
fallback_language = "english"

# Mixed language support
allow_code_switching = True
```

## ğŸ“Š **Performance Metrics**

### **Response Quality:**
- **Accuracy**: 90%+ relevant farming advice
- **Language**: Natural Hindi with proper grammar
- **Length**: 3-4 sentences (optimal for farmers)
- **Actionability**: Practical, implementable advice

### **Performance Benchmarks:**
```
Model: llama3.2:3b
Hardware: 8GB RAM, 4-core CPU
Response Time: 2-5 seconds average
Memory Usage: ~4GB during generation
Throughput: 12-20 responses per minute
```

### **Quality Examples:**

**High Quality Response:**
```
Input: "à¤—à¥‡à¤¹à¥‚à¤‚ à¤®à¥‡à¤‚ à¤ªà¥€à¤²à¥‡ à¤ªà¤¤à¥à¤¤à¥‡ à¤¹à¥‹ à¤°à¤¹à¥‡ à¤¹à¥ˆà¤‚"
Output: "à¤¯à¤¹ à¤¨à¤¾à¤‡à¤Ÿà¥à¤°à¥‹à¤œà¤¨ à¤•à¥€ à¤•à¤®à¥€ à¤¹à¥ˆà¥¤ à¤¤à¥à¤°à¤‚à¤¤ à¤¯à¥‚à¤°à¤¿à¤¯à¤¾ 50 à¤•à¤¿à¤²à¥‹ à¤ªà¥à¤°à¤¤à¤¿ à¤à¤•à¤¡à¤¼ à¤¡à¤¾à¤²à¥‡à¤‚à¥¤ 
à¤¸à¤¿à¤‚à¤šà¤¾à¤ˆ à¤•à¥‡ à¤¸à¤¾à¤¥ à¤¦à¥‡à¤‚ à¤”à¤° 10 à¤¦à¤¿à¤¨ à¤®à¥‡à¤‚ à¤¸à¥à¤§à¤¾à¤° à¤¦à¤¿à¤–à¥‡à¤—à¤¾à¥¤"
Quality: âœ… Specific, actionable, correct
```

**Fallback Response:**
```
Input: "à¤®à¥Œà¤¸à¤® à¤•à¥ˆà¤¸à¤¾ à¤°à¤¹à¥‡à¤—à¤¾"
Output: "à¤®à¥Œà¤¸à¤® à¤•à¥€ à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤•à¥‡ à¤²à¤¿à¤ à¤¸à¥à¤¥à¤¾à¤¨à¥€à¤¯ à¤®à¥Œà¤¸à¤® à¤µà¤¿à¤­à¤¾à¤— à¤¸à¥‡ à¤¸à¤‚à¤ªà¤°à¥à¤• à¤•à¤°à¥‡à¤‚à¥¤"
Quality: âœ… Appropriate fallback
```

## ğŸ”§ **Advanced Features**

### **Context Awareness:**
- **Entity Integration**: Uses detected crops, quantities, time
- **Conversation History**: Maintains session context
- **Regional Adaptation**: Adjusts advice for local conditions

### **Fallback Mechanisms:**
- **LLM Failure**: Provides rule-based responses
- **Low Confidence**: Asks for clarification
- **Unknown Intent**: Suggests contacting experts

### **Response Optimization:**
- **Length Control**: Keeps responses concise
- **Language Mixing**: Handles Hindi-English code-switching
- **Technical Terms**: Uses farmer-friendly vocabulary

## ğŸ§ª **Testing & Validation**

### **Test Categories:**
1. **Intent Accuracy**: Correct response for each farming intent
2. **Language Quality**: Natural Hindi with proper grammar
3. **Technical Accuracy**: Correct agricultural information
4. **Response Time**: Performance under load
5. **Fallback Handling**: Graceful error handling

### **Quality Assurance:**
```python
# Test response quality
def test_response_quality(intent, query, expected_keywords):
    result = llm.process_farmer_query(query)
    response = result["llm_response"]
    
    # Check for expected keywords
    assert any(keyword in response for keyword in expected_keywords)
    
    # Check response length
    assert 50 <= len(response) <= 300
    
    # Check language appropriateness
    assert contains_hindi_text(response)
```

## ğŸš¨ **Troubleshooting**

### **Common Issues:**

**Problem: "LLM not responding"**
```bash
# Check Ollama status
curl http://localhost:11434/api/tags

# Restart Ollama
ollama serve
```

**Problem: "Slow responses"**
```python
# Use faster model
model_name = "llama3.2:1b"

# Reduce max_tokens
max_tokens = 100
```

**Problem: "Poor Hindi quality"**
```python
# Improve system prompt
system_prompt = "à¤†à¤ª à¤à¤• à¤¹à¤¿à¤‚à¤¦à¥€ à¤­à¤¾à¤·à¥€ à¤•à¥ƒà¤·à¤¿ à¤µà¤¿à¤¶à¥‡à¤·à¤œà¥à¤ à¤¹à¥ˆà¤‚à¥¤ à¤•à¥‡à¤µà¤² à¤¶à¥à¤¦à¥à¤§ à¤¹à¤¿à¤‚à¤¦à¥€ à¤®à¥‡à¤‚ à¤œà¤µà¤¾à¤¬ à¤¦à¥‡à¤‚à¥¤"
```

## ğŸ¯ **Production Deployment**

### **Recommended Setup:**
- **Hardware**: 8GB+ RAM, 4+ CPU cores
- **Model**: llama3.2:3b (balanced performance)
- **Monitoring**: Response time and quality tracking
- **Backup**: Fallback responses for LLM failures

### **Scaling Options:**
- **Horizontal**: Multiple Ollama instances
- **Vertical**: Larger models (8B parameters)
- **Cloud**: Ollama on cloud servers
- **API**: Switch to commercial LLM APIs

## ğŸŒ¾ **Impact for Farmers**

### **Benefits:**
- **Natural Interaction**: Speak in native language
- **Intelligent Responses**: Context-aware farming advice
- **Real-time Help**: Immediate assistance
- **Expert Knowledge**: Access to agricultural expertise
- **24/7 Availability**: Always available support

### **Use Cases:**
- **Field Consultation**: On-the-spot farming advice
- **Problem Solving**: Disease and pest identification
- **Planning**: Crop selection and timing
- **Market Intelligence**: Price and selling guidance
- **Learning**: Agricultural knowledge transfer

---

## ğŸ‰ **Ready for Intelligent Farming!**

The LLM system provides human-like, intelligent responses to farmer queries, completing the STT â†’ NLP â†’ LLM pipeline for comprehensive agricultural assistance.

**Happy Farming with AI!** ğŸŒ¾ğŸ¤–âœ¨
