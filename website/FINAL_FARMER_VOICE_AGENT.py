#!/usr/bin/env python3
"""
üåæ FINAL FARMER VOICE AGENT üåæ
Complete Real-Time Voice Call System for Farmers
Production Ready - All Tests Passed
"""

import os
import tempfile
from datetime import datetime
from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
import requests

app = Flask(__name__)
CORS(app)

# Load API key
GROQ_API_KEY = None
try:
    env_file = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'llm', '.env')
    if os.path.exists(env_file):
        with open(env_file, 'r', encoding='utf-8') as f:
            for line in f:
                if 'GROQ_API_KEY=' in line:
                    GROQ_API_KEY = line.split('=', 1)[1].strip()
                    break
    print(f"‚úÖ API Key: {'READY' if GROQ_API_KEY else 'MISSING'}")
except Exception as e:
    print(f"‚ùå API key error: {e}")

def get_farming_advice(query):
    """Get expert farming advice from AI"""
    print(f"üåæ Farmer Query: {query}")
    
    if not GROQ_API_KEY:
        return "API key ‡§ï‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§π‡•à, ‡§≠‡§æ‡§à‡•§"
    
    try:
        url = "https://api.groq.com/openai/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {GROQ_API_KEY}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": "llama3-70b-8192",
            "messages": [
                {
                    "role": "system", 
                    "content": """‡§Ü‡§™ ‡§è‡§ï ‡§Ö‡§®‡•Å‡§≠‡§µ‡•Ä ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§ï‡•É‡§∑‡§ø ‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û ‡§π‡•à‡§Ç‡•§ 

‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á‡§®‡•á ‡§ï‡§æ ‡§§‡§∞‡•Ä‡§ï‡§æ:
- ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á‡§Ç
- 2-3 ‡§µ‡§æ‡§ï‡•ç‡§Ø ‡§Æ‡•á‡§Ç practical ‡§∏‡§≤‡§æ‡§π ‡§¶‡•á‡§Ç
- "‡§≠‡§æ‡§à" ‡§Ø‡§æ "‡§ú‡•Ä" ‡§ï‡§æ ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç
- ‡§¨‡§ø‡§≤‡•ç‡§ï‡•Å‡§≤ phone call ‡§ï‡•Ä ‡§§‡§∞‡§π ‡§¨‡§æ‡§§ ‡§ï‡§∞‡•á‡§Ç
- ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§π‡§æ‡§∞‡§ø‡§ï ‡§î‡§∞ actionable advice ‡§¶‡•á‡§Ç

‡§µ‡§ø‡§∑‡§Ø expertise:
- ‡§´‡§∏‡§≤ ‡§ï‡•Ä ‡§ñ‡•á‡§§‡•Ä (‡§ó‡•á‡§π‡•Ç‡§Ç, ‡§ß‡§æ‡§®, ‡§Æ‡§ï‡•ç‡§ï‡§æ, ‡§∏‡§¨‡•ç‡§ú‡•Ä)
- ‡§ñ‡§æ‡§¶ ‡§î‡§∞ ‡§â‡§∞‡•ç‡§µ‡§∞‡§ï
- ‡§ï‡•Ä‡§ü-‡§™‡§§‡§Ç‡§ó ‡§®‡§ø‡§Ø‡§Ç‡§§‡•ç‡§∞‡§£
- ‡§∏‡§ø‡§Ç‡§ö‡§æ‡§à ‡§î‡§∞ ‡§™‡§æ‡§®‡•Ä ‡§™‡•ç‡§∞‡§¨‡§Ç‡§ß‡§®
- ‡§Æ‡§Ç‡§°‡•Ä ‡§≠‡§æ‡§µ ‡§î‡§∞ ‡§¨‡§ø‡§ï‡•ç‡§∞‡•Ä
- ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§ï‡•Ä ‡§ú‡§æ‡§Ç‡§ö"""
                },
                {"role": "user", "content": query}
            ],
            "temperature": 0.7,
            "max_tokens": 150
        }
        
        response = requests.post(url, json=payload, headers=headers, timeout=20)
        
        if response.status_code == 200:
            result = response.json()
            ai_response = result["choices"][0]["message"]["content"].strip()
            print(f"‚úÖ AI Response: {ai_response}")
            return ai_response
        else:
            print(f"‚ùå API Error: {response.status_code}")
            return "AI ‡§Æ‡•á‡§Ç ‡§ï‡•Å‡§õ ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§π‡•à, ‡§≠‡§æ‡§à‡•§ ‡§´‡§ø‡§∞ ‡§∏‡•á ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•á‡§Ç‡•§"
            
    except Exception as e:
        print(f"‚ùå Exception: {e}")
        return "‡§®‡•á‡§ü‡§µ‡§∞‡•ç‡§ï ‡§ï‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§π‡•à, ‡§≠‡§æ‡§à‡•§ ‡§ï‡§®‡•á‡§ï‡•ç‡§∂‡§® ‡§ö‡•á‡§ï ‡§ï‡§∞‡•á‡§Ç‡•§"

def generate_hindi_voice(text):
    """Generate Hindi voice from text"""
    print(f"üîä Generating voice: {text[:50]}...")
    
    try:
        from gtts import gTTS
        tts = gTTS(text=text, lang="hi", slow=False)
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
        tts.save(temp_file.name)
        print(f"‚úÖ Voice generated: {temp_file.name}")
        return temp_file.name
    except Exception as e:
        print(f"‚ùå Voice generation error: {e}")
        return None

@app.route('/')
def index():
    """Final Farmer Voice Agent Interface"""
    return """
    <!DOCTYPE html>
    <html lang="hi">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>üåæ Farmer Voice Agent - AI ‡§ï‡•É‡§∑‡§ø ‡§∏‡§≤‡§æ‡§π‡§ï‡§æ‡§∞</title>
        
        <style>
            * { margin: 0; padding: 0; box-sizing: border-box; }
            
            body {
                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
                background: linear-gradient(135deg, #2E8B57 0%, #228B22 50%, #32CD32 100%);
                min-height: 100vh;
                display: flex;
                align-items: center;
                justify-content: center;
                color: white;
                overflow-x: hidden;
            }
            
            .main-container {
                background: rgba(255, 255, 255, 0.95);
                border-radius: 30px;
                padding: 40px;
                text-align: center;
                color: #2c3e50;
                max-width: 600px;
                width: 90%;
                box-shadow: 0 30px 60px rgba(0,0,0,0.3);
                position: relative;
                overflow: hidden;
            }
            
            .main-container::before {
                content: '';
                position: absolute;
                top: -50%;
                left: -50%;
                width: 200%;
                height: 200%;
                background: linear-gradient(45deg, transparent, rgba(46, 139, 87, 0.1), transparent);
                transform: rotate(45deg);
                animation: shine 4s infinite;
            }
            
            @keyframes shine {
                0% { transform: translateX(-100%) translateY(-100%) rotate(45deg); }
                100% { transform: translateX(100%) translateY(100%) rotate(45deg); }
            }
            
            .header {
                position: relative;
                z-index: 1;
                margin-bottom: 30px;
            }
            
            .header h1 {
                font-size: 32px;
                margin-bottom: 10px;
                background: linear-gradient(45deg, #2E8B57, #228B22);
                -webkit-background-clip: text;
                -webkit-text-fill-color: transparent;
                background-clip: text;
            }
            
            .header p {
                color: #666;
                font-size: 18px;
            }
            
            .call-interface {
                position: relative;
                z-index: 1;
                margin: 30px 0;
            }
            
            .call-status {
                font-size: 22px;
                font-weight: bold;
                margin: 25px 0;
                padding: 20px;
                border-radius: 15px;
                background: #f8f9fa;
                color: #495057;
                transition: all 0.3s ease;
                border: 2px solid #e9ecef;
            }
            
            .call-status.connected {
                background: linear-gradient(45deg, #d4edda, #c3e6cb);
                color: #155724;
                border-color: #28a745;
                animation: connectedPulse 2s infinite;
            }
            
            .call-status.listening {
                background: linear-gradient(45deg, #cce5ff, #b3d9ff);
                color: #004085;
                border-color: #007bff;
                animation: listeningWave 1.5s infinite;
            }
            
            .call-status.speaking {
                background: linear-gradient(45deg, #fff3cd, #ffeaa7);
                color: #856404;
                border-color: #ffc107;
                animation: speakingBounce 1s infinite;
            }
            
            @keyframes connectedPulse {
                0%, 100% { transform: scale(1); box-shadow: 0 0 0 0 rgba(40, 167, 69, 0.7); }
                50% { transform: scale(1.02); box-shadow: 0 0 0 20px rgba(40, 167, 69, 0); }
            }
            
            @keyframes listeningWave {
                0%, 100% { box-shadow: 0 0 0 0 rgba(0, 123, 255, 0.7); }
                50% { box-shadow: 0 0 0 25px rgba(0, 123, 255, 0); }
            }
            
            @keyframes speakingBounce {
                0%, 100% { transform: translateY(0); }
                50% { transform: translateY(-5px); }
            }
            
            .call-buttons {
                margin: 30px 0;
            }
            
            .call-btn {
                width: 90px;
                height: 90px;
                border-radius: 50%;
                border: none;
                font-size: 35px;
                cursor: pointer;
                margin: 0 20px;
                transition: all 0.3s ease;
                position: relative;
                z-index: 1;
                box-shadow: 0 10px 20px rgba(0,0,0,0.2);
            }
            
            .call-btn.start {
                background: linear-gradient(45deg, #28a745, #20c997);
                color: white;
            }
            
            .call-btn.end {
                background: linear-gradient(45deg, #dc3545, #e74c3c);
                color: white;
            }
            
            .call-btn:hover {
                transform: translateY(-5px) scale(1.05);
                box-shadow: 0 15px 30px rgba(0,0,0,0.3);
            }
            
            .call-btn:active {
                transform: translateY(-2px) scale(1.02);
            }
            
            .call-btn:disabled {
                opacity: 0.5;
                cursor: not-allowed;
                transform: none;
            }
            
            .conversation {
                background: #f8f9fa;
                border-radius: 20px;
                padding: 25px;
                margin: 25px 0;
                text-align: left;
                max-height: 400px;
                overflow-y: auto;
                display: none;
                position: relative;
                z-index: 1;
                border: 2px solid #e9ecef;
            }
            
            .conversation h4 {
                color: #495057;
                margin-bottom: 20px;
                text-align: center;
                font-size: 18px;
            }
            
            .message {
                margin: 15px 0;
                padding: 15px 20px;
                border-radius: 15px;
                animation: messageSlide 0.4s ease;
                position: relative;
                box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            }
            
            @keyframes messageSlide {
                from { opacity: 0; transform: translateY(20px); }
                to { opacity: 1; transform: translateY(0); }
            }
            
            .message.farmer {
                background: linear-gradient(45deg, #e3f2fd, #bbdefb);
                margin-left: 40px;
                border-left: 5px solid #2196f3;
            }
            
            .message.ai {
                background: linear-gradient(45deg, #e8f5e8, #c8e6c9);
                margin-right: 40px;
                border-left: 5px solid #4caf50;
            }
            
            .message-header {
                font-weight: bold;
                margin-bottom: 10px;
                font-size: 14px;
                display: flex;
                justify-content: space-between;
                align-items: center;
            }
            
            .message-text {
                font-size: 16px;
                line-height: 1.5;
                margin-bottom: 10px;
            }
            
            .message-time {
                font-size: 12px;
                color: #666;
                text-align: right;
            }
            
            .features {
                background: rgba(46, 139, 87, 0.1);
                border: 2px solid #2E8B57;
                border-radius: 15px;
                padding: 20px;
                margin: 25px 0;
                position: relative;
                z-index: 1;
            }
            
            .features h4 {
                color: #2E8B57;
                margin-bottom: 15px;
                text-align: center;
            }
            
            .features ul {
                list-style: none;
                padding: 0;
            }
            
            .features li {
                padding: 8px 0;
                color: #495057;
                font-size: 14px;
            }
            
            .features li::before {
                content: 'üåæ ';
                margin-right: 8px;
            }
            
            .status-indicator {
                display: inline-block;
                width: 12px;
                height: 12px;
                border-radius: 50%;
                margin-right: 8px;
                animation: statusBlink 2s infinite;
            }
            
            .status-indicator.active {
                background: #28a745;
            }
            
            .status-indicator.inactive {
                background: #6c757d;
            }
            
            @keyframes statusBlink {
                0%, 50% { opacity: 1; }
                51%, 100% { opacity: 0.5; }
            }
        </style>
    </head>
    <body>
        <div class="main-container">
            <div class="header">
                <h1>üåæ AI ‡§ï‡•É‡§∑‡§ø ‡§∏‡§≤‡§æ‡§π‡§ï‡§æ‡§∞</h1>
                <p>Real-Time Voice Call System for Farmers</p>
            </div>
            
            <div class="features">
                <h4>üéØ ‡§µ‡§ø‡§∂‡•á‡§∑‡§§‡§æ‡§è‡§Ç</h4>
                <ul>
                    <li>‡§´‡§∏‡§≤ ‡§ï‡•Ä ‡§ñ‡•á‡§§‡•Ä ‡§î‡§∞ ‡§¨‡•Å‡§Ü‡§à ‡§ï‡•Ä ‡§∏‡§≤‡§æ‡§π</li>
                    <li>‡§ñ‡§æ‡§¶ ‡§î‡§∞ ‡§â‡§∞‡•ç‡§µ‡§∞‡§ï ‡§ï‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä</li>
                    <li>‡§ï‡•Ä‡§ü-‡§™‡§§‡§Ç‡§ó ‡§®‡§ø‡§Ø‡§Ç‡§§‡•ç‡§∞‡§£ ‡§ï‡•á ‡§â‡§™‡§æ‡§Ø</li>
                    <li>‡§∏‡§ø‡§Ç‡§ö‡§æ‡§à ‡§î‡§∞ ‡§™‡§æ‡§®‡•Ä ‡§™‡•ç‡§∞‡§¨‡§Ç‡§ß‡§®</li>
                    <li>‡§Æ‡§Ç‡§°‡•Ä ‡§≠‡§æ‡§µ ‡§î‡§∞ ‡§¨‡§ø‡§ï‡•ç‡§∞‡•Ä ‡§ï‡•Ä ‡§∏‡§≤‡§æ‡§π</li>
                </ul>
            </div>
            
            <div class="call-interface">
                <div class="call-status" id="callStatus">
                    <span class="status-indicator inactive" id="statusIndicator"></span>
                    üìû Call ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§§‡•à‡§Ø‡§æ‡§∞
                </div>
                
                <div class="call-buttons">
                    <button class="call-btn start" id="startCall" onclick="startVoiceCall()">
                        üìû
                    </button>
                    <button class="call-btn end" id="endCall" onclick="endVoiceCall()" disabled>
                        üìµ
                    </button>
                </div>
            </div>
            
            <div class="conversation" id="conversation">
                <h4>üí¨ Voice Conversation</h4>
                <div id="messages"></div>
            </div>
        </div>
        
        <script>
            let recognition = null;
            let isCallActive = false;
            let currentAudio = null;
            let callStartTime = null;
            let messageCount = 0;
            let isRecognitionRunning = false;
            let recognitionTimeout = null;
            let consecutiveErrors = 0;
            let lastRecognitionTime = 0;
            
            function updateCallStatus(message, type = '') {
                const statusEl = document.getElementById('callStatus');
                const indicatorEl = document.getElementById('statusIndicator');

                statusEl.innerHTML = `<span class="status-indicator ${type === 'connected' || type === 'listening' || type === 'speaking' ? 'active' : 'inactive'}" id="statusIndicator"></span>${message}`;
                statusEl.className = `call-status ${type}`;

                console.log('üìû Status:', message);
            }

            function safeStartRecognition() {
                // Clear any existing timeout
                if (recognitionTimeout) {
                    clearTimeout(recognitionTimeout);
                    recognitionTimeout = null;
                }

                // Only start if call is active and recognition is not running
                if (!isCallActive) {
                    console.log('üõë Call not active, skipping recognition start');
                    return;
                }

                if (isRecognitionRunning) {
                    console.log('üîÑ Recognition already running, skipping start');
                    return;
                }

                if (!recognition) {
                    console.log('‚ùå Recognition object not available');
                    return;
                }

                // Prevent too frequent restarts
                const now = Date.now();
                if (now - lastRecognitionTime < 2000) {
                    console.log('‚è≥ Too soon to restart, waiting...');
                    recognitionTimeout = setTimeout(() => {
                        safeStartRecognition();
                    }, 3000);
                    return;
                }

                // Check for too many consecutive errors
                if (consecutiveErrors >= 5) {
                    console.log('üõë Too many errors, pausing recognition for 10 seconds...');
                    updateCallStatus('üîÑ Voice system recovering...', 'processing');
                    consecutiveErrors = 0;
                    recognitionTimeout = setTimeout(() => {
                        if (isCallActive) {
                            updateCallStatus('üé§ Call Connected - ‡§Ü‡§™ ‡§¨‡•ã‡§≤‡•á‡§Ç!', 'listening');
                            safeStartRecognition();
                        }
                    }, 10000);
                    return;
                }

                try {
                    console.log('üé§ Starting recognition safely...');
                    lastRecognitionTime = now;
                    recognition.start();
                } catch (error) {
                    console.log('‚ö†Ô∏è Recognition start error:', error.message);
                    isRecognitionRunning = false;
                    consecutiveErrors++;

                    // Retry after a longer delay
                    recognitionTimeout = setTimeout(() => {
                        if (isCallActive && !isRecognitionRunning) {
                            safeStartRecognition();
                        }
                    }, 3000);
                }
            }
            
            function startVoiceCall() {
                console.log('üìû Starting voice call...');
                
                if (!('webkitSpeechRecognition' in window)) {
                    alert('‚ùå Voice recognition not supported! Please use Chrome or Edge browser.');
                    return;
                }
                
                isCallActive = true;
                callStartTime = new Date();
                messageCount = 0;
                consecutiveErrors = 0;
                lastRecognitionTime = 0;
                
                document.getElementById('startCall').disabled = true;
                document.getElementById('endCall').disabled = false;
                document.getElementById('conversation').style.display = 'block';
                
                // Initialize speech recognition
                recognition = new webkitSpeechRecognition();
                recognition.continuous = false;
                recognition.interimResults = false;
                recognition.lang = 'hi-IN';
                
                recognition.onstart = function() {
                    updateCallStatus('üé§ Call Connected - ‡§Ü‡§™ ‡§¨‡•ã‡§≤‡•á‡§Ç!', 'listening');
                    isRecognitionRunning = true;
                    console.log('‚úÖ Voice recognition started');

                    // Clear any pending timeout
                    if (recognitionTimeout) {
                        clearTimeout(recognitionTimeout);
                        recognitionTimeout = null;
                    }

                    // Reset error count on successful start
                    if (consecutiveErrors > 0) {
                        console.log(`üîÑ Resetting error count from ${consecutiveErrors} to 0`);
                        consecutiveErrors = 0;
                    }
                };
                
                recognition.onresult = function(event) {
                    const transcript = event.results[0][0].transcript.trim();
                    const confidence = event.results[0][0].confidence;

                    console.log('üé§ Voice input:', transcript, 'Confidence:', confidence.toFixed(2));

                    // Reset consecutive errors on successful recognition
                    consecutiveErrors = 0;

                    // Accept any transcript with reasonable length, ignore confidence for now
                    if (transcript && transcript.length >= 2) {
                        console.log('‚úÖ Processing voice input:', transcript);
                        processVoiceInput(transcript);
                    } else {
                        console.log('‚ö†Ô∏è Empty or too short transcript, restarting...');
                        isRecognitionRunning = false;
                        consecutiveErrors++;
                        if (isCallActive) {
                            recognitionTimeout = setTimeout(() => {
                                safeStartRecognition();
                            }, 2000);
                        }
                    }
                };
                
                recognition.onerror = function(event) {
                    console.error('‚ùå Voice error:', event.error);
                    isRecognitionRunning = false;
                    consecutiveErrors++;

                    if (event.error === 'not-allowed') {
                        alert('‚ùå Microphone access denied! Please allow microphone access and try again.');
                        endVoiceCall();
                        return;
                    }

                    if (!isCallActive) {
                        return;
                    }

                    // Handle different error types with progressive delays
                    let retryDelay = Math.min(2000 + (consecutiveErrors * 1000), 8000);

                    switch (event.error) {
                        case 'no-speech':
                            console.log('‚ö†Ô∏è No speech detected, restarting...');
                            retryDelay = Math.min(3000 + (consecutiveErrors * 500), 10000);
                            break;
                        case 'audio-capture':
                            console.log('‚ö†Ô∏è Audio capture error, restarting...');
                            retryDelay = Math.min(4000 + (consecutiveErrors * 1000), 12000);
                            break;
                        case 'network':
                            console.log('‚ö†Ô∏è Network error, restarting...');
                            retryDelay = Math.min(5000 + (consecutiveErrors * 1000), 15000);
                            break;
                        default:
                            console.log('‚ö†Ô∏è Other error, restarting...');
                            retryDelay = Math.min(3000 + (consecutiveErrors * 1000), 10000);
                    }

                    console.log(`üîÑ Will retry in ${retryDelay}ms (errors: ${consecutiveErrors})`);

                    // Safe restart with progressive delay
                    recognitionTimeout = setTimeout(() => {
                        safeStartRecognition();
                    }, retryDelay);
                };

                recognition.onend = function() {
                    console.log('üîÑ Voice recognition ended');
                    isRecognitionRunning = false;

                    if (isCallActive) {
                        // Only restart if no timeout is already set
                        if (!recognitionTimeout) {
                            recognitionTimeout = setTimeout(() => {
                                safeStartRecognition();
                            }, 800);
                        }
                    }
                };
                
                // Start recognition safely
                safeStartRecognition();

                // Welcome message
                setTimeout(() => {
                    const welcomeMsg = '‡§®‡§Æ‡§∏‡•ç‡§ï‡§æ‡§∞ ‡§≠‡§æ‡§à! ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡§æ AI ‡§ï‡•É‡§∑‡§ø ‡§∏‡§≤‡§æ‡§π‡§ï‡§æ‡§∞ ‡§π‡•Ç‡§Ç‡•§ ‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§ñ‡•á‡§§‡•Ä ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§ï‡•ã‡§à ‡§≠‡•Ä ‡§∏‡§µ‡§æ‡§≤ ‡§™‡•Ç‡§õ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç‡•§';
                    addMessage('ai', welcomeMsg);
                    playVoiceResponse(welcomeMsg);
                }, 2000);
            }
            
            function endVoiceCall() {
                console.log('üìµ Ending voice call...');
                isCallActive = false;
                isRecognitionRunning = false;

                // Clear any pending timeouts
                if (recognitionTimeout) {
                    clearTimeout(recognitionTimeout);
                    recognitionTimeout = null;
                }

                if (recognition) {
                    recognition.stop();
                    recognition = null;
                }

                if (currentAudio) {
                    currentAudio.pause();
                    currentAudio = null;
                }
                
                document.getElementById('startCall').disabled = false;
                document.getElementById('endCall').disabled = true;
                
                const callDuration = callStartTime ? Math.floor((new Date() - callStartTime) / 1000) : 0;
                updateCallStatus(`üìµ Call Ended (${callDuration}s, ${messageCount} messages)`);
                
                setTimeout(() => {
                    updateCallStatus('üìû Call ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§§‡•à‡§Ø‡§æ‡§∞');
                }, 5000);
            }
            
            async function processVoiceInput(transcript) {
                console.log('üîÑ Processing voice input:', transcript);
                
                // Stop current audio
                if (currentAudio) {
                    currentAudio.pause();
                    currentAudio = null;
                }
                
                // Add farmer message
                addMessage('farmer', transcript);
                messageCount++;
                
                // Update status
                updateCallStatus('ü§ñ AI ‡§∏‡•ã‡§ö ‡§∞‡§π‡§æ ‡§π‡•à...', 'speaking');
                
                try {
                    // Get AI response
                    const response = await fetch('/api/farming-advice', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ query: transcript })
                    });
                    
                    const result = await response.json();
                    console.log('üì¶ AI response received:', result.success);
                    
                    if (result.success) {
                        const aiResponse = result.response;
                        addMessage('ai', aiResponse);
                        messageCount++;
                        await playVoiceResponse(aiResponse);
                    } else {
                        const errorMsg = '‡§Æ‡§æ‡§´ ‡§ï‡§∞‡•á‡§Ç ‡§≠‡§æ‡§à, ‡§ï‡•Å‡§õ ‡§§‡§ï‡§®‡•Ä‡§ï‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§π‡•à‡•§ ‡§´‡§ø‡§∞ ‡§∏‡•á ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•á‡§Ç‡•§';
                        addMessage('ai', errorMsg);
                        await playVoiceResponse(errorMsg);
                    }
                } catch (error) {
                    console.error('‚ùå Voice processing error:', error);
                    const errorMsg = '‡§®‡•á‡§ü‡§µ‡§∞‡•ç‡§ï ‡§ï‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§π‡•à ‡§≠‡§æ‡§à‡•§ ‡§ï‡§®‡•á‡§ï‡•ç‡§∂‡§® ‡§ö‡•á‡§ï ‡§ï‡§∞‡•á‡§Ç‡•§';
                    addMessage('ai', errorMsg);
                    await playVoiceResponse(errorMsg);
                }
            }
            
            async function playVoiceResponse(text) {
                console.log('üîä Playing voice response...');
                updateCallStatus('üîä AI ‡§¨‡•ã‡§≤ ‡§∞‡§π‡§æ ‡§π‡•à...', 'speaking');
                
                try {
                    const response = await fetch('/api/generate-voice', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ text: text })
                    });
                    
                    if (response.ok) {
                        const audioBlob = await response.blob();
                        const audioUrl = URL.createObjectURL(audioBlob);
                        currentAudio = new Audio(audioUrl);
                        
                        currentAudio.onended = function() {
                            console.log('‚úÖ Voice response finished');
                            currentAudio = null;
                            if (isCallActive) {
                                updateCallStatus('üé§ Call Connected - ‡§Ü‡§™ ‡§¨‡•ã‡§≤‡•á‡§Ç!', 'listening');
                                // Ensure recognition is restarted after audio finishes
                                recognitionTimeout = setTimeout(() => {
                                    safeStartRecognition();
                                }, 1200);
                            }
                        };
                        
                        currentAudio.onerror = function(e) {
                            console.error('‚ùå Audio playback error:', e);
                            if (isCallActive) {
                                updateCallStatus('üé§ Call Connected - ‡§Ü‡§™ ‡§¨‡•ã‡§≤‡•á‡§Ç!', 'listening');
                            }
                        };
                        
                        await currentAudio.play();
                        console.log('‚úÖ Voice response playing');
                    } else {
                        console.error('‚ùå Voice generation failed');
                        if (isCallActive) {
                            updateCallStatus('üé§ Call Connected - ‡§Ü‡§™ ‡§¨‡•ã‡§≤‡•á‡§Ç!', 'listening');
                        }
                    }
                } catch (error) {
                    console.error('‚ùå Voice playback error:', error);
                    if (isCallActive) {
                        updateCallStatus('üé§ Call Connected - ‡§Ü‡§™ ‡§¨‡•ã‡§≤‡•á‡§Ç!', 'listening');
                    }
                }
            }
            
            function addMessage(speaker, text) {
                const messagesEl = document.getElementById('messages');
                const messageEl = document.createElement('div');
                messageEl.className = `message ${speaker}`;
                
                const speakerName = speaker === 'farmer' ? 'üë®‚Äçüåæ ‡§Ü‡§™' : 'ü§ñ AI ‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û';
                const timestamp = new Date().toLocaleTimeString('hi-IN');
                
                messageEl.innerHTML = `
                    <div class="message-header">
                        <span>${speakerName}</span>
                        <span>${timestamp}</span>
                    </div>
                    <div class="message-text">${text}</div>
                `;
                
                messagesEl.appendChild(messageEl);
                messagesEl.scrollTop = messagesEl.scrollHeight;
                
                console.log('üí¨ Message added:', speakerName);
            }
            
            // Initialize
            window.onload = function() {
                console.log('üåæ Farmer Voice Agent ready');
                updateCallStatus('üìû Call ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§§‡•à‡§Ø‡§æ‡§∞');
            };
            
            // Handle page unload
            window.onbeforeunload = function() {
                if (isCallActive) {
                    endVoiceCall();
                }
            };
        </script>
    </body>
    </html>
    """

@app.route('/api/farming-advice', methods=['POST'])
def farming_advice_api():
    """Main farming advice API"""
    print("üåæ === FARMING ADVICE API ===")
    
    try:
        data = request.get_json()
        query = data.get('query', '').strip()
        
        if not query:
            return jsonify({"success": False, "error": "Empty query"})
        
        # Get farming advice
        advice = get_farming_advice(query)
        
        return jsonify({
            "success": True,
            "response": advice,
            "timestamp": datetime.now().isoformat()
        })
        
    except Exception as e:
        print(f"‚ùå Farming Advice API Error: {e}")
        return jsonify({"success": False, "error": str(e)})

@app.route('/api/generate-voice', methods=['POST'])
def generate_voice_api():
    """Voice generation API"""
    print("üîä === VOICE GENERATION API ===")
    
    try:
        data = request.get_json()
        text = data.get('text', '').strip()
        
        if not text:
            return jsonify({"success": False, "error": "Empty text"})
        
        audio_file = generate_hindi_voice(text)
        
        if audio_file:
            return send_file(audio_file, as_attachment=True, download_name="voice_response.mp3")
        else:
            return jsonify({"success": False, "error": "Voice generation failed"})
            
    except Exception as e:
        print(f"‚ùå Voice Generation API Error: {e}")
        return jsonify({"success": False, "error": str(e)})

@app.route('/api/health', methods=['GET'])
def health_check():
    """System health check"""
    return jsonify({
        "status": "healthy",
        "api_key": "present" if GROQ_API_KEY else "missing",
        "timestamp": datetime.now().isoformat(),
        "system": "Farmer Voice Agent v1.0"
    })

if __name__ == '__main__':
    print("üåæ" + "="*60 + "üåæ")
    print("üåæ FINAL FARMER VOICE AGENT - PRODUCTION READY üåæ")
    print("üåæ" + "="*60 + "üåæ")
    print("üé§ Real-Time Voice Call System for Farmers")
    print("ü§ñ AI-Powered Agricultural Expert")
    print("üáÆüá≥ Complete Hindi Language Support")
    print("üìû Phone Call Like Experience")
    print("=" * 64)
    
    print(f"‚úÖ API Key Status: {'READY' if GROQ_API_KEY else 'MISSING'}")
    print(f"‚úÖ Voice Recognition: Browser STT")
    print(f"‚úÖ AI Processing: Groq LLM")
    print(f"‚úÖ Voice Generation: Google TTS")
    print(f"‚úÖ Language: Hindi")
    
    print(f"\nüöÄ Starting production server...")
    print(f"üåê URL: http://localhost:5000")
    print(f"üí° Press Ctrl+C to stop")
    print("üåæ" + "="*60 + "üåæ")
    
    app.run(debug=False, host='0.0.0.0', port=5000)
