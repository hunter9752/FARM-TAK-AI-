#!/usr/bin/env python3
"""
Working Voice Agent - New Approach
Guaranteed working voice call system for farmers
"""

import os
import tempfile
from datetime import datetime
from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
import requests

app = Flask(__name__)
CORS(app)

# Load API key
GROQ_API_KEY = None
try:
    env_file = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'llm', '.env')
    if os.path.exists(env_file):
        with open(env_file, 'r', encoding='utf-8') as f:
            for line in f:
                if 'GROQ_API_KEY=' in line:
                    GROQ_API_KEY = line.split('=', 1)[1].strip()
                    break
    print(f"‚úÖ API Key: {'Loaded' if GROQ_API_KEY else 'Not found'}")
except Exception as e:
    print(f"‚ùå API key error: {e}")

def get_farming_advice(query):
    """Get farming advice from AI"""
    print(f"üåæ Farmer Query: {query}")
    
    if not GROQ_API_KEY:
        return "API key ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡•Ä ‡§π‡•à‡•§"
    
    try:
        url = "https://api.groq.com/openai/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {GROQ_API_KEY}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": "llama3-70b-8192",
            "messages": [
                {
                    "role": "system", 
                    "content": "‡§Ü‡§™ ‡§è‡§ï ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§ï‡•É‡§∑‡§ø ‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û ‡§π‡•à‡§Ç‡•§ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç 2-3 ‡§µ‡§æ‡§ï‡•ç‡§Ø ‡§Æ‡•á‡§Ç practical ‡§∏‡§≤‡§æ‡§π ‡§¶‡•á‡§Ç‡•§ '‡§≠‡§æ‡§à' ‡§Ø‡§æ '‡§ú‡•Ä' ‡§ï‡§æ use ‡§ï‡§∞‡•á‡§Ç‡•§"
                },
                {"role": "user", "content": query}
            ],
            "temperature": 0.7,
            "max_tokens": 100
        }
        
        response = requests.post(url, json=payload, headers=headers, timeout=15)
        
        if response.status_code == 200:
            result = response.json()
            advice = result["choices"][0]["message"]["content"].strip()
            print(f"‚úÖ AI Advice: {advice}")
            return advice
        else:
            print(f"‚ùå API Error: {response.status_code}")
            return "AI ‡§Æ‡•á‡§Ç ‡§ï‡•Å‡§õ ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§π‡•à‡•§"
            
    except Exception as e:
        print(f"‚ùå Exception: {e}")
        return "‡§®‡•á‡§ü‡§µ‡§∞‡•ç‡§ï ‡§ï‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§π‡•à‡•§"

def create_audio(text):
    """Create audio from text"""
    print(f"üîä Creating audio: {text}")
    
    try:
        from gtts import gTTS
        tts = gTTS(text=text, lang="hi", slow=False)
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
        tts.save(temp_file.name)
        print(f"‚úÖ Audio created: {temp_file.name}")
        return temp_file.name
    except Exception as e:
        print(f"‚ùå Audio error: {e}")
        return None

@app.route('/')
def index():
    """Working voice agent interface"""
    return """
    <!DOCTYPE html>
    <html lang="hi">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>üé§ Working Voice Agent</title>
        
        <style>
            body {
                font-family: Arial, sans-serif;
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                min-height: 100vh;
                margin: 0;
                padding: 20px;
                color: white;
                display: flex;
                align-items: center;
                justify-content: center;
            }
            
            .container {
                background: rgba(255, 255, 255, 0.95);
                border-radius: 25px;
                padding: 40px;
                text-align: center;
                color: #333;
                max-width: 600px;
                width: 100%;
                box-shadow: 0 20px 40px rgba(0,0,0,0.2);
            }
            
            h1 { color: #2c3e50; margin-bottom: 20px; }
            
            .status {
                font-size: 20px;
                font-weight: bold;
                margin: 20px 0;
                padding: 15px;
                border-radius: 10px;
                background: #f8f9fa;
                color: #666;
            }
            
            .status.listening {
                background: #d4edda;
                color: #155724;
                animation: pulse 2s infinite;
            }
            
            .status.processing {
                background: #fff3cd;
                color: #856404;
                animation: pulse 1s infinite;
            }
            
            @keyframes pulse {
                0% { opacity: 1; }
                50% { opacity: 0.8; }
                100% { opacity: 1; }
            }
            
            .btn {
                padding: 15px 30px;
                font-size: 18px;
                border: none;
                border-radius: 10px;
                cursor: pointer;
                margin: 10px;
                font-weight: bold;
                transition: all 0.3s;
            }
            
            .btn.success { background: #28a745; color: white; }
            .btn.danger { background: #dc3545; color: white; }
            .btn:hover { transform: translateY(-2px); }
            .btn:disabled { opacity: 0.6; cursor: not-allowed; }
            
            .conversation {
                background: #f8f9fa;
                border-radius: 15px;
                padding: 20px;
                margin: 20px 0;
                max-height: 400px;
                overflow-y: auto;
                text-align: left;
                display: none;
            }
            
            .message {
                margin: 12px 0;
                padding: 15px;
                border-radius: 12px;
                animation: fadeIn 0.3s;
            }
            
            .message.farmer {
                background: linear-gradient(45deg, #e3f2fd, #bbdefb);
                margin-left: 20px;
                border-left: 4px solid #2196f3;
            }
            
            .message.ai {
                background: linear-gradient(45deg, #e8f5e8, #c8e6c9);
                margin-right: 20px;
                border-left: 4px solid #4caf50;
            }
            
            @keyframes fadeIn {
                from { opacity: 0; transform: translateY(10px); }
                to { opacity: 1; transform: translateY(0); }
            }
            
            .test-section {
                background: #e9ecef;
                border-radius: 10px;
                padding: 20px;
                margin: 20px 0;
                text-align: left;
            }
            
            input[type="text"] {
                width: 70%;
                padding: 10px;
                font-size: 16px;
                border: 2px solid #ddd;
                border-radius: 5px;
                margin-right: 10px;
            }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>üé§ Working Voice Agent</h1>
            <p>Real-time voice call system for farmers</p>
            
            <div class="status" id="status">
                Ready for voice call
            </div>
            
            <div>
                <button class="btn success" id="startBtn" onclick="startVoiceCall()">
                    üé§ Start Voice Call
                </button>
                <button class="btn danger" id="stopBtn" onclick="stopVoiceCall()" disabled>
                    üìµ End Call
                </button>
            </div>
            
            <div class="test-section">
                <h4>üß™ Test First:</h4>
                <input type="text" id="testInput" placeholder="Type: ‡§ó‡•á‡§π‡•Ç‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ñ‡§æ‡§¶ ‡§ï‡•Ä ‡§∏‡§≤‡§æ‡§π ‡§¶‡•ã">
                <button onclick="testAPI()" style="padding: 8px 16px; background: #007bff; color: white; border: none; border-radius: 5px;">
                    Test
                </button>
                <div id="testResult" style="margin-top: 10px;"></div>
            </div>
            
            <div class="conversation" id="conversation">
                <h4>üí¨ Voice Conversation:</h4>
                <div id="messages"></div>
            </div>
        </div>
        
        <script>
            let recognition = null;
            let isCallActive = false;
            let currentAudio = null;
            
            function updateStatus(message, type = '') {
                const statusEl = document.getElementById('status');
                statusEl.textContent = message;
                statusEl.className = `status ${type}`;
                console.log('Status:', message);
            }
            
            async function testAPI() {
                const query = document.getElementById('testInput').value.trim();
                if (!query) {
                    document.getElementById('testInput').value = '‡§ó‡•á‡§π‡•Ç‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ñ‡§æ‡§¶ ‡§ï‡•Ä ‡§∏‡§≤‡§æ‡§π ‡§¶‡•ã';
                    return;
                }
                
                console.log('Testing API with:', query);
                document.getElementById('testResult').innerHTML = '<div style="color: #007bff;">üîÑ Testing...</div>';
                
                try {
                    const response = await fetch('/api/voice', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ query: query })
                    });
                    
                    const result = await response.json();
                    console.log('API result:', result);
                    
                    if (result.success) {
                        document.getElementById('testResult').innerHTML = 
                            `<div style="background: #d4edda; padding: 10px; border-radius: 5px; color: #155724; margin-top: 10px;">
                                <strong>‚úÖ Working!</strong><br>
                                ${result.response}
                            </div>`;
                    } else {
                        document.getElementById('testResult').innerHTML = 
                            `<div style="background: #f8d7da; padding: 10px; border-radius: 5px; color: #721c24; margin-top: 10px;">
                                <strong>‚ùå Error:</strong> ${result.error}
                            </div>`;
                    }
                } catch (error) {
                    document.getElementById('testResult').innerHTML = 
                        `<div style="background: #f8d7da; padding: 10px; border-radius: 5px; color: #721c24; margin-top: 10px;">
                            <strong>‚ùå Network Error:</strong> ${error.message}
                        </div>`;
                }
            }
            
            function startVoiceCall() {
                if (!('webkitSpeechRecognition' in window)) {
                    alert('‚ùå Voice recognition not supported! Use Chrome or Edge.');
                    return;
                }
                
                isCallActive = true;
                document.getElementById('startBtn').disabled = true;
                document.getElementById('stopBtn').disabled = false;
                document.getElementById('conversation').style.display = 'block';
                
                recognition = new webkitSpeechRecognition();
                recognition.continuous = false;
                recognition.interimResults = false;
                recognition.lang = 'hi-IN';
                
                recognition.onstart = function() {
                    updateStatus('üé§ Listening... Speak now!', 'listening');
                };
                
                recognition.onresult = function(event) {
                    const transcript = event.results[0][0].transcript.trim();
                    const confidence = event.results[0][0].confidence;
                    
                    console.log('Voice:', transcript, 'Confidence:', confidence);
                    
                    if (transcript && confidence > 0.3) {
                        processVoice(transcript);
                    } else {
                        if (isCallActive) {
                            setTimeout(() => recognition.start(), 1000);
                        }
                    }
                };
                
                recognition.onerror = function(event) {
                    console.error('Voice error:', event.error);
                    if (event.error === 'not-allowed') {
                        alert('‚ùå Microphone access denied!');
                        stopVoiceCall();
                    }
                };
                
                recognition.onend = function() {
                    if (isCallActive) {
                        setTimeout(() => recognition.start(), 500);
                    }
                };
                
                recognition.start();
                
                setTimeout(() => {
                    addMessage('ai', '‡§®‡§Æ‡§∏‡•ç‡§ï‡§æ‡§∞! ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡§æ AI ‡§ï‡•É‡§∑‡§ø ‡§∏‡§≤‡§æ‡§π‡§ï‡§æ‡§∞ ‡§π‡•Ç‡§Ç‡•§ ‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§ñ‡•á‡§§‡•Ä ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§ï‡•ã‡§à ‡§≠‡•Ä ‡§∏‡§µ‡§æ‡§≤ ‡§™‡•Ç‡§õ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç‡•§');
                }, 1000);
            }
            
            function stopVoiceCall() {
                isCallActive = false;
                
                if (recognition) recognition.stop();
                if (currentAudio) {
                    currentAudio.pause();
                    currentAudio = null;
                }
                
                document.getElementById('startBtn').disabled = false;
                document.getElementById('stopBtn').disabled = true;
                updateStatus('Call ended');
            }
            
            async function processVoice(transcript) {
                console.log('Processing voice:', transcript);
                
                if (currentAudio) {
                    currentAudio.pause();
                    currentAudio = null;
                }
                
                addMessage('farmer', transcript);
                updateStatus('üß† AI is thinking...', 'processing');
                
                try {
                    const response = await fetch('/api/voice', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ query: transcript })
                    });
                    
                    const result = await response.json();
                    console.log('Voice result:', result);
                    
                    if (result.success) {
                        addMessage('ai', result.response);
                        await playAudio(result.response);
                    } else {
                        const errorMsg = '‡§Æ‡§æ‡§´ ‡§ï‡§∞‡•á‡§Ç, ‡§ï‡•Å‡§õ ‡§ó‡§≤‡§§‡•Ä ‡§π‡•Å‡§à ‡§π‡•à‡•§';
                        addMessage('ai', errorMsg);
                        await playAudio(errorMsg);
                    }
                } catch (error) {
                    console.error('Voice processing error:', error);
                    const errorMsg = '‡§®‡•á‡§ü‡§µ‡§∞‡•ç‡§ï ‡§ï‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§π‡•à‡•§';
                    addMessage('ai', errorMsg);
                    await playAudio(errorMsg);
                }
            }
            
            async function playAudio(text) {
                updateStatus('üîä AI is speaking...', 'processing');
                
                try {
                    const response = await fetch('/api/audio', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ text: text })
                    });
                    
                    if (response.ok) {
                        const audioBlob = await response.blob();
                        const audioUrl = URL.createObjectURL(audioBlob);
                        currentAudio = new Audio(audioUrl);
                        
                        currentAudio.onended = function() {
                            currentAudio = null;
                            if (isCallActive) {
                                updateStatus('üé§ Listening... Speak now!', 'listening');
                            }
                        };
                        
                        await currentAudio.play();
                    }
                } catch (error) {
                    console.error('Audio error:', error);
                    if (isCallActive) {
                        updateStatus('üé§ Listening... Speak now!', 'listening');
                    }
                }
            }
            
            function addMessage(speaker, text) {
                const messagesEl = document.getElementById('messages');
                const messageEl = document.createElement('div');
                messageEl.className = `message ${speaker}`;
                
                const speakerName = speaker === 'farmer' ? 'üë®‚Äçüåæ ‡§Ü‡§™' : 'ü§ñ AI ‡§∏‡§≤‡§æ‡§π‡§ï‡§æ‡§∞';
                const timestamp = new Date().toLocaleTimeString('hi-IN');
                
                messageEl.innerHTML = `
                    <div style="font-weight: bold; margin-bottom: 8px;">${speakerName}</div>
                    <div style="font-size: 16px; line-height: 1.4;">${text}</div>
                    <div style="font-size: 12px; color: #666; margin-top: 8px;">${timestamp}</div>
                `;
                
                messagesEl.appendChild(messageEl);
                messagesEl.scrollTop = messagesEl.scrollHeight;
            }
            
            // Auto-test on load
            window.onload = function() {
                console.log('Working voice agent ready');
                document.getElementById('testInput').value = '‡§ó‡•á‡§π‡•Ç‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ñ‡§æ‡§¶ ‡§ï‡•Ä ‡§∏‡§≤‡§æ‡§π ‡§¶‡•ã';
                setTimeout(testAPI, 1000);
            };
        </script>
    </body>
    </html>
    """

@app.route('/api/voice', methods=['POST'])
def handle_voice():
    """Handle voice input"""
    print("üé§ === VOICE API CALLED ===")
    
    try:
        data = request.get_json()
        query = data.get('query', '').strip()
        
        print(f"üë®‚Äçüåæ Voice Input: {query}")
        
        if not query:
            return jsonify({"success": False, "error": "Empty query"})
        
        # Get farming advice
        advice = get_farming_advice(query)
        
        return jsonify({
            "success": True,
            "response": advice,
            "timestamp": datetime.now().isoformat()
        })
        
    except Exception as e:
        print(f"‚ùå Voice API Error: {e}")
        return jsonify({"success": False, "error": str(e)})

@app.route('/api/audio', methods=['POST'])
def handle_audio():
    """Handle audio generation"""
    print("üîä === AUDIO API CALLED ===")
    
    try:
        data = request.get_json()
        text = data.get('text', '').strip()
        
        print(f"üîä Audio Text: {text}")
        
        if not text:
            return jsonify({"success": False, "error": "Empty text"})
        
        audio_file = create_audio(text)
        
        if audio_file:
            return send_file(audio_file, as_attachment=True, download_name="response.mp3")
        else:
            return jsonify({"success": False, "error": "Audio generation failed"})
            
    except Exception as e:
        print(f"‚ùå Audio API Error: {e}")
        return jsonify({"success": False, "error": str(e)})

if __name__ == '__main__':
    print("üé§ Starting Working Voice Agent...")
    print("üåæ Simple and Reliable Voice Call System")
    print("=" * 50)
    
    print(f"‚úÖ API Key: {'Loaded' if GROQ_API_KEY else 'Not found'}")
    
    print(f"\nüöÄ Starting server...")
    print(f"üåê URL: http://localhost:5012")
    print(f"üí° Press Ctrl+C to stop")
    
    app.run(debug=True, host='0.0.0.0', port=5012)
